Data Science Manifesto


Introduction


In the age where everything seems to be about “numbers” and “what’s the rate”, data science practice is a serious business. This class really kickstarted my data science journey, and through all of the work that we did, alongside the readings, I would like to anchor my manifesto in four principles. These are an answer to what I think are both the promise and pitfalls of data: (1) AI Transparency and the Challenge of Black Boxes, (2) Feminist approaches to data, or Data Feminism, (3) the values of Open-Source and Open Access, and (4) Exploration, and Curiosity. Together I aspire to hold them throughout the way that I practice with data. I have seen that algorithms and models, without transparency, have the potential to hurt people and perpetuate inequalities, cautioned by Cathy O'Neil as "weapons of math destruction" that perpetuate bias. But I have also seen how well-treated data has the power to lay bare truths and unleash the potential for good to change. The following describes each of these principles, how it relates to personal motivators (I really really enjoy using numbers and information to prove concepts), and how I saw it evolve through coursework and projects.


On data and information 


During our projects this term, data was the raw, naked facts we first dealt with - whether the CSV of hourly weather observations for Project 1 with columns for temperature, timestamp, and station ID, the streams of x-, y-, and z-axis accelerometer readings from our sensors for Project 2, or the raw grade records and major codes consumed into pandas for DataCamp’s “Loading Data into pandas” tutorial. At this stage, these values existed as nothing more than bytes on disk, meaningless without the imposition of structure upon them. We transformed this raw data into information that we could act upon and communicate with by cleaning, annotating, and aggregating: giving column labels descriptive names, parsing date, dropping missing records; combining student records on major and GPAs to learn that Biology students averaged 3.5 in Economics 307; transforming data streams of sensor readings to tidy DataFrames. That activity of structuring and enriching - filtering, sorting, grouping, and visualizing - exchanged numbers and strings for propositions like “the average outdoor temperature on May 12 was 22.4 °C” or “computer science first-years performed better than classmates in economics,” creating information both useful to talk about and to communicate.


From there, we ascended to knowledge by making connections and looking for patterns across our layers of information. In Project 5's cluster analysis of U.S. parks, we translated city clusters to "high-amenity urban parks" and "low-amenity rural parks" and linked these clusters to patterns of population density.  Such conclusions - park amenities conditioned on urbanness, inspection scores linked to economic class - were domain knowledge describing how and *why* our variables interacted. And lastly, we reached **wisdom** by translating that knowledge to actionable recommendations: in the final project's predictions, we could propose including qualitative data streams to improve prediction for price and  volume movements. By climbing the DIKW pyramid with purpose -collecting raw data, sorting data into information, linking knowledge through analysis, and translating wisdom to decision-making - we made our data science more than just data-crunching. It produced ethically mindful, context-specific insight that could inform real-world action, highlighted in our course by awareness of transparency, equity, and community effect.






Artificial intelligence transparency and the black box challenge


Algorithms are opaque "black boxes" with impenetrable interiors. In my opinion, blind trust in incomprehensible models could have catastrophic consequences for everyone, not just the techies. Models that are being used predict who is given a loan, a job, may appear objective, but always recreate prejudice and are opaque. It dawned on me that these systems should have to lose their mystique. In practice, this is to prefer models that I can look at for sense, or at least demand explanations for algorithmic outputs. Janelle Shane’s book takes this argument a step further. By trying to do absurd things (such as create paint colors or ice cream flavors) with neural nets, she proves that AI often makes absurd or harmful “mistakes,” and therefore cannot blindly be trusted. Her statement -  “the danger of AI isn’t that it’s too smart, but that it’s not smart enough” - reminds the reader that an AI system may well do just the thing that it has been trained to do, but not the desired thing.


For example, for Project 1, I did raw weather data calculations to estimate the formula for the dew point using algorithms manually. I trusted the outputs since I knew every step along the way. By analogy, if I had invoked some black box function of some library without knowing where the function came from, I would have been nervous. Similarly, for Project 3 I joined student course and outcomes information and charted grade distributions. Rather than entrust auto piloted intuition, I took the time to read the data, and dictionary, which helped me be more efficient rather than just plugging in stuff into chat-gpt and asking it to give me the code without any understanding, aggregate data by major, and interpret the charts for myself. I learned that even the simplest statistics have the potential to mislead without scrutiny. These exercises have led me to hold every model provisionally: I will continue performing checks, chart outputs, and question every conclusion the machine makes on its own behalf. Lastly, I promise to push code and algorithms to github so that others -and I, too- are able to look inside to see how the numbers give rise to conclusions. By doing so, I show respect to O’Neil’s warning against inferring bias hiding in the shadows and avoid the generation of new “toxic cocktails” of data injustice. 




Data Feminism


Data is never neutral. I have learned, from reading D’Ignazio & Klein’s Data Feminism, that every dataset, every analysis is a choice about who is included and how. Data Feminism calls data science to pay attention to equity, positionality, and justice in practice. I strongly subscribe to this mantra. It is to think about whose voices are included in data and whose are missing, and to use data to challenge instead of to amplify power imbalances. As D’Ignazio & Klein remind us, data science is “both personal and political,” and every data project should “support justice in decision-making.”


With Project 4 (Freedom of Expression index visualization), I chose data on a very social theme to try things out. That exercise provided for me the sense that there are human lives behind the data whose rights may not always be treated equally. As someone from India, I have a sensitive awareness of how policy reality and social reality shape data - free-speech data, for example, may undercount minority or opposition voices, especially in the last few years. That project prompted the question for me: Who generated this data, and why? Who does this visualization speak to, and who are the people who can be harmed? The concept of Data Feminism has encouraged me to interrogate data first instead of just taking things at face value but rather questioning the sources. From now on, I shall keep this in perspective: for example, looking at college outcomes (Project 3) or user data (Project 4 personal data requests), I shall keep justice and diversity in perspective. I shall have data representing the experience of the underrepresented groups and have the conclusions not silencing or misrepresenting anyone. Additionally, I am hoping to explore conducting design workshops or interviews with affected communities, ensuring their concerns shape which metrics we collect and which visualizations we build especially for my socio-economics studies. By following a feminist methodology of “nothing about us without us,” I will use data to address community-defined problemAs the authors wrote, we have to begin “a journey toward justice … in our data-driven world”, and that has been at the core of the way I will continue to practice.




The ideals of open-source and open-access


I think data science would thrive on openness. Open-source software and open data have led to learning on my part: I have utilized libraries like pandas, NumPy, scikit-learn, tensorflow as well as mapping visualization tools, to mention but a few which are open-sourced. I have witnessed firsthand in class and on projects how sharing code accelerates learning and creativity. Publicly available data or data on platforms like GitHub open up data for experimenting on my part as well as for verification or extending research on the part of other people. 


As another commentator opines, “much of AI’s creation and evolution have happened thanks to open-source development and diffusion”. Openness promotes transparency and accountability, which is the essence of what I want to achieve through algorithm demystification.. During Project 4 Part 1, I ‘officially’ joined GitHub and enjoyed being able to see everyone else's code up online. I also grew frustrated at the closed systems: for example, in Project 1 I struggled to upload the Whitman weather CSV on Google Colab before I found a workaround. During Project 4 Part 3, the measures differed across indices -  a warning note on the way closed or opaque data systems strangle understanding. These frustrations reinforced the commitment to stay away from these pitfalls. Going forward, I promise to release my code and data online where possible so that other people can replicate and stand on the shoulders of my research. I shall be an advocate for open data sources and open APIs since I now have first-hand experience of how inaccessible data hinders analysis. In short, I am excited to continue creating and utilizing open tools: this not only promotes learning and cooperation (as openness "promotes transparency, accountability, competition, and innovation") but also guarantees that my data projects benefit the greater community, not just me.


Discovery, and curiosity


Data science can be made to seem dry or technical, but I have learned that experimenting in a whimsical way is the key to learning. Numbers are entertaining to play with because they can disprove or prove an idea, but the path to knowledge is never straightforward. Real insight comes from trying and more importantly even failing. When applying this mindset to class projects, I enjoyed the process. To give you an example, in the final portion of Project 3 I had the freedom to select my own analysis: I compared the distributions of Chemistry grades for Biology and non-Biology majors, and plotted histograms to show the distinction. This open-ended project was challenging but also fun. For the final project, I loved playing around with different variables and seeing what worked best - this was also something I could see the effects of changing the variables. With Project 5, clustering parks and recreation data, I tried different feature sets and visualized the result using a combination of scatterplots and dendrograms. Every choice -  from selecting “Parks per 10,000 residents” to the number of clusters -  was a mini experiment that I learned from. Though I tried to conduct serious analysis, I knew that I enjoyed the trial-and-error process, much like a chemist experimenting with variables, especially playing around with code and seeing my silly mistakes. 


This style is fostered in the way that experts like Janelle Shane collaborate with AI. She makes a hobby of whimsical experiments: teaching neural networks about wacky data sets (bowel movements, knitting patterns, ice cream flavors) and delighting in the ridiculous outputs. The theory is that curiosity-driven experiments like these illustrate the capabilities and pitfalls of AI in an entertaining way. Following that model, in my head, every data set is a playground for questions. Having laid the goal out plainly as “I like to explore how to use numbers to show things,” I turn questions, visualizations, and code until insight is gained or how to ask ‘weird questions’ . The mindset is that I have no shame in posing dumb questions or outside-the-box methods; these are the things that lead to real insight on a regular basis. Going forward, I will let curiosity drive the way - prototyping fresh analysis, scraping small bites to answer a question, and revising visualizations. By maintaining a mindset of openness to experiment and curiosity, I keep data science activities creative and responsive and exciting for myself, instead of it becoming a corporate task.


Conclusion


In this manifesto, I declare how I now practice data science as a human endeavor at its core. It calls for honesty about algorithms, consideration of power and justice, free giving back, and perpetual questioning with curiosity. These values - openness, feminism, transparency, and play -  are the learnings that I have taken from readings like Cathy O'Neil’s Weapons of Math Destruction, from D'Ignazio & Klein’s Data Feminism, and from observing AI’s idiosyncrasies in Janelle Shane’s writing. These are also evident in projects and personal investigation. To me, data science at its essence is about using data not only to answer questions, but also to pose better questions about society. Going forward, I promise to keep these values close - building tools that are interpretable, centering analyses in equity, making work accessible, and celebrating the process of discovery. In this way, I commit to a data science practice that is ethical, accessible, that fosters collaboration, and is joyous.